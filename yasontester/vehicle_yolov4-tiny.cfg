[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=32
subdivisions=16
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.0013
burn_in=1000
max_batches = 12000
policy=steps
steps=9600,10800 # 80% do max_batches , 90% do max_batches
scales=.1,.1


#weights_reject_freq=1001
#ema_alpha=0.9998
#equidistant_point=1000
#num_sigmas_reject_badlabels=3
#badlabels_rejection_percentage=0.2

[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky


# 01
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

# 02
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

# 03
[route]
layers=-1
groups=2
group_id=1

# 04
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# 05
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# 06
[route]
layers = -1,-2

# 07
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

# 08
[route]
layers = -6,-1

# 09
[maxpool]
size=2
stride=2

# 10
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 11
[route]
layers=-1
groups=2
group_id=1

# 12
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

# 13
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

# 14
[route]
layers = -1,-2

# 15
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 16
[route]
layers = -6,-1

# 17
[maxpool]
size=2
stride=2

# 18
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 19
[route]
layers=-1
groups=2
group_id=1

# 20
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 21
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 22
[route]
layers = -1,-2

# 23
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 24
[route]
layers = -6,-1

# 25
[maxpool]
size=2
stride=2

# 26
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

##################################

# 27
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# 28
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

# 29
[convolutional]
size=1
stride=1
pad=1
filters=33
activation=linear


# 30
[yolo]
mask = 3,4,5
anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
classes=6
num=6
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
resize=1.5
nms_kind=greedynms
beta_nms=0.6
#new_coords=1
#scale_x_y = 2.0


# 31
[route]
layers = -4


# 32
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# 33
[upsample]
stride=2

# 34
[route]
layers = -1, 23   # -1, 23 

# 35
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

# 36
[convolutional]
size=1
stride=1
pad=1
filters=33
activation=linear

# 37
[yolo]
mask = 1,2,3
anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
classes=6
num=6
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
resize=1.5
nms_kind=greedynms
beta_nms=0.6
#new_coords=1
#scale_x_y = 2.0
